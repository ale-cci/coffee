-- breaks up file in one or multiple tokens
import "./std/sys" as sys
import "./std/string" as string
import "./std/io" as io

import "./peeker" as peeker
-- import "./errors" as errors


alias Token = struct {
    chr* type,
    chr* value,

    int line,
    int char_of_line,
    chr* filename,

    Token* next,
    Token* prev,
}


alias ParseCtx = struct {
    chr* filename,
    int line,
    int char_of_line,

    Token* root,
    Token* curr_token,
}


Token* push_token(ParseCtx* c, str type, value) {
    Token* root = (Token*) sys.malloc(sizeof(Token))
    root.type = type
    root.value = value
    root.filename = c.filename
    root.line = c.line
    root.char_of_line = c.char_of_line
    root.prev = c.curr_token
    root.next = null

    if c.curr_token != null {
        c.curr_token.next = root
    }
    c.curr_token = root

    if c.root == null {
        c.root = root
    }

    return root
}



-- takes a peeker in input, returns the sequence of tokens
-- depending on the first character, start parsing a
-- specific token.
-- Here are the rules:
--
--    [0-9] -> INT_NUMBER
--    [a-zA-Z_] -> WORD
--    ["] -> STRING
--    ['] -> CHR
--    [+-/*=[({])}|] -> OPERATOR or COMMENT
Token* tokenize(peeker.PeekerInfo* p, bool keep_comments) {
    ParseCtx* ctx = (ParseCtx*) sys.malloc(sizeof(ParseCtx))
    ctx.filename = p.filename
    ctx.root = null
    ctx.curr_token = null

    int max_token_size = 128
    chr* buf = (chr*) null

    int idx = 0


    c := peeker.read(p)
    for ; p.eof == false ; {
        ctx.line = p.line
        ctx.char_of_line = p.char_of_line

        if c == '\x00' {
            -- eof
            c = peeker.read(p)

        } elif string.is_digit(c) {
            buf = sys.malloc(max_token_size)

            for idx = 0 ; string.is_digit(c); c = peeker.read(p) {
                buf[idx] = c
                idx = idx + 1
                sys.assert(idx < max_token_size, "digit too large")
            }
            buf[idx] = '\x00'

            push_token(ctx, "NUMBER", buf)

        } elif string.is_letter(c) | c == '_' {
            buf = sys.malloc(max_token_size)

            for idx = 0 ; string.is_letter(c) | string.is_digit(c) | c == '_'; c = peeker.read(p) {
                buf[idx] = c
                idx = idx + 1
                sys.assert(idx < max_token_size, "WORD too large")
            }
            buf[idx] = '\x00'
            push_token(ctx, "WORD", buf)

        } elif string.is_whitespace(c) {
            -- ignore whitespaces and tabs for now
            c = peeker.read(p)

        } elif c == '"' | c == '`' {
            buf = read_string(p, c)
            c = peeker.read(p)

            push_token(ctx, "STRING", buf)
        } elif c == '\x27' {
            buf = sys.malloc(max_token_size)
            buf[0] = c
            c = peeker.read(p)
            for idx = 1; c != '\x27'; c = peeker.read(p) {
                sys.assert(idx < max_token_size - 2, "char too large")
                buf[idx] = c
                idx = idx + 1
            }
            buf[idx] = c
            buf[idx + 1] = '\x00'
            c = peeker.read(p)

            push_token(ctx, "CHR", buf)

        } elif c == '\n' {
            push_token(ctx, "NL", "\n")
            c = peeker.read(p)
        } elif c == '-' {
            c = peeker.read(p)
            if c != '-' {
                push_token(ctx, "OPERATOR", "-")
                continue
            }

            -- if next token is a '-' start parsing a comment
            -- start parsing a comment block
            buf = sys.malloc(max_token_size)
            buf[0] = '-'
            for idx = 1; c != '\n' & c != '\x00' ; c = peeker.read(p) {
                buf[idx] = c
                idx = idx + 1
            }
            buf[idx] = '\x00'

            if keep_comments {
                push_token(ctx, "COMMENT", buf)
            } else {
                sys.free((chr*) buf)
            }
        } else {
            -- check for operator
            if c > '\x7E' {
                io.printf("%d:%d error: found non ascii token: '%c' (%d)\n", ctx.line, ctx.char_of_line, c, c)
                sys.exit(1)
            }

            -- TODO: some operators are composed by two or more characters
            -- ex. != or ==

            prev_c := c

            c = peeker.read(p)

            chr* type = "OPERATOR"
            if prev_c == '=' & c == '=' {
                io.asprintf(&buf, "==")
                c = peeker.read(p)
            } elif prev_c == '!' & c == '=' {
                io.asprintf(&buf, "!=")
                c = peeker.read(p)
            } elif prev_c == '>' & c == '=' {
                io.asprintf(&buf, ">=")
                c = peeker.read(p)
            } elif prev_c == '<' & c == '=' {
                io.asprintf(&buf, "<=")
                c = peeker.read(p)
            } elif prev_c == '.' & c == '.' {
                -- ensure next token is . otherwise tokenerror raised
                c = peeker.read(p)
                if c != '.' {
                    io.printf("error on ..\n")
                    -- err := new_error("unrecognized operand ..")
                    sys.exit(1)
                } else {
                    io.asprintf(&buf, "...")
                    type = "KEYWORD"
                }
                c = peeker.read(p)
            } else {
                buf = sys.malloc(2)
                buf[0] = prev_c
                buf[1] = '\x00'
            }
            push_token(ctx, type, buf)
        }
    }

    -- set curr_token as eof
    push_token(ctx, "EOF", "")

    Token* root = ctx.root
    sys.free((chr*) ctx)
    return (Token*) root
}


str read_string(peeker.PeekerInfo* p, chr delimeter) {
    int str_size = 64
    buf := sys.malloc(str_size)
    buf[0] = delimeter

    -- read string content
    c := peeker.read(p)
    int idx
    for idx = 1; c != delimeter; c = peeker.read(p) {
        sys.assert(c != '\x00', "lexer: reached end of file while scanning for 'STRING' token")
        -- resize
        if idx == str_size -2 {
            str_size = str_size * 2
            buf = sys.realloc(buf, str_size)
        }

        buf[idx] = c
        idx = idx + 1
    }

    -- read terminator character
    buf[idx] = c
    buf[idx + 1] = '\x00'
    return buf
}
